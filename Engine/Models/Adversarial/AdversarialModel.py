#!/usr/bin/env python3
# -*- coding: utf-8 -*-

__author__ = 'Kayuã Oleques Paim'
__email__ = 'kayuaolequesp@gmail.com'
__version__ = '{1}.{0}.{1}'
__initial_data__ = '2022/06/01'
__last_update__ = '2025/10/29'
__credits__ = ['Kayuã Oleques']

# MIT License
#
# Copyright (c) 2025 Synthetic Ocean AI
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

import sys
import numpy
from typing import Optional, Dict, List

# Note: This assumes VanillaGenerator and VanillaDiscriminator are already framework-agnostic
# If they're not available, you'll need to import them from your framework-agnostic implementations
try:
    from Engine.Models.Adversarial.VanillaGenerator import VanillaGenerator
    from Engine.Models.Adversarial.VanillaDiscriminator import VanillaDiscriminator
except ImportError as error:
    print(f"Warning: Could not import VanillaGenerator/VanillaDiscriminator: {error}")
    print("Make sure these classes are framework-agnostic implementations.")


# Default configuration constants
DEFAULT_ADVERSARIAL_LATENT_DIMENSION = 128
DEFAULT_ADVERSARIAL_INTERMEDIARY_ACTIVATION = "leaky_relu"
DEFAULT_ADVERSARIAL_LAST_ACTIVATION_LAYER = "sigmoid"
DEFAULT_ADVERSARIAL_DROPOUT_DECAY_RATE_G = 0.2
DEFAULT_ADVERSARIAL_DROPOUT_DECAY_RATE_D = 0.4
DEFAULT_ADVERSARIAL_INITIALIZER_MEAN = 0.0
DEFAULT_ADVERSARIAL_INITIALIZER_DEVIATION = 0.5
DEFAULT_ADVERSARIAL_DENSE_LAYERS_SETTINGS_G = [128]
DEFAULT_ADVERSARIAL_DENSE_LAYERS_SETTINGS_D = [128]


class AdversarialModel:
    """
    AdversarialModel (Framework Agnostic)

    Combines a generator and a discriminator in a unified adversarial model.
    This class allows for seamless integration of both models in a Generative 
    Adversarial Network (GAN) framework, with methods for initializing, 
    configuring, and interacting with the generator and discriminator networks.

    This implementation automatically detects and uses either TensorFlow or PyTorch
    through the underlying VanillaGenerator and VanillaDiscriminator classes.

    Attributes:
        latent_dimension (int):
            Dimensionality of the latent space used by the generator.
        output_shape (int):
            Shape of the output generated by the generator and evaluated by the discriminator.
        activation_function (str):
            Activation function applied to intermediate layers.
        initializer_mean (float):
            Mean of the normal distribution used for weight initialization.
        initializer_deviation (float):
            Standard deviation of the normal distribution used for weight initialization.
        dropout_decay_rate_g (float):
            Dropout decay rate applied to the generator layers.
        dropout_decay_rate_d (float):
            Dropout decay rate applied to the discriminator layers.
        last_layer_activation (str):
            Activation function used for the last layer of both generator and discriminator.
        dense_layer_sizes_g (list):
            List of integers specifying the number of units per dense layer in the generator.
        dense_layer_sizes_d (list):
            List of integers specifying the number of units per dense layer in the discriminator.
        dataset_type (type):
            Data type used for input data (default: numpy.float32).
        number_samples_per_class (dict | None):
            Optional dictionary containing the number of samples per class.

    Example:
        >>> model = AdversarialModel(
        ...     latent_dimension=100,
        ...     output_shape=784,
        ...     activation_function='relu',
        ...     initializer_mean=0.0,
        ...     initializer_deviation=0.02,
        ...     dropout_decay_rate_g=0.3,
        ...     dropout_decay_rate_d=0.3,
        ...     last_layer_activation='sigmoid',
        ...     dense_layer_sizes_g=[512, 256],
        ...     dense_layer_sizes_d=[512, 256],
        ...     number_samples_per_class={"number_classes": 10}
        ... )
        >>> generator = model.get_generator()
        >>> discriminator = model.get_discriminator()
    """

    def __init__(self,
                 latent_dimension: int = DEFAULT_ADVERSARIAL_LATENT_DIMENSION,
                 output_shape: int = 128,
                 activation_function: str = DEFAULT_ADVERSARIAL_INTERMEDIARY_ACTIVATION,
                 initializer_mean: float = DEFAULT_ADVERSARIAL_INITIALIZER_MEAN,
                 initializer_deviation: float = DEFAULT_ADVERSARIAL_INITIALIZER_DEVIATION,
                 dropout_decay_rate_g: float = DEFAULT_ADVERSARIAL_DROPOUT_DECAY_RATE_G,
                 dropout_decay_rate_d: float = DEFAULT_ADVERSARIAL_DROPOUT_DECAY_RATE_D,
                 last_layer_activation: str = DEFAULT_ADVERSARIAL_LAST_ACTIVATION_LAYER,
                 dense_layer_sizes_g: Optional[List[int]] = None,
                 dense_layer_sizes_d: Optional[List[int]] = None,
                 dataset_type: type = numpy.float32,
                 number_samples_per_class: Optional[Dict[str, int]] = None):
        """
        Initializes the AdversarialModel by constructing both the generator and discriminator networks.

        Args:
            latent_dimension (int):
                Dimensionality of the latent space used by the generator.
            output_shape (int):
                Shape of the generated output.
            activation_function (str):
                Activation function applied to all hidden layers.
            initializer_mean (float):
                Mean of the normal distribution for weight initialization.
            initializer_deviation (float):
                Standard deviation of the normal distribution for weight initialization.
            dropout_decay_rate_g (float):
                Dropout decay rate applied to the generator layers.
            dropout_decay_rate_d (float):
                Dropout decay rate applied to the discriminator layers.
            last_layer_activation (str):
                Activation function for the last layer of both models.
            dense_layer_sizes_g (list, optional):
                List of integers specifying the number of units per dense layer in the generator.
            dense_layer_sizes_d (list, optional):
                List of integers specifying the number of units per dense layer in the discriminator.
            dataset_type (type, optional):
                Data type of the input dataset (default: numpy.float32).
            number_samples_per_class (dict | None, optional):
                Optional dictionary containing metadata about the number of samples per class.
        """

        if dense_layer_sizes_d is None:
            dense_layer_sizes_d = DEFAULT_ADVERSARIAL_DENSE_LAYERS_SETTINGS_D.copy()

        if dense_layer_sizes_g is None:
            dense_layer_sizes_g = DEFAULT_ADVERSARIAL_DENSE_LAYERS_SETTINGS_G.copy()

        # Store configuration
        self._latent_dimension = latent_dimension
        self._output_shape = output_shape
        self._activation_function = activation_function
        self._initializer_mean = initializer_mean
        self._initializer_deviation = initializer_deviation
        self._dropout_decay_rate_g = dropout_decay_rate_g
        self._dropout_decay_rate_d = dropout_decay_rate_d
        self._last_layer_activation = last_layer_activation
        self._dense_layer_sizes_g = dense_layer_sizes_g
        self._dense_layer_sizes_d = dense_layer_sizes_d
        self._dataset_type = dataset_type
        self._number_samples_per_class = number_samples_per_class

        # Initialize generator
        self._generator = VanillaGenerator(
            latent_dimension=latent_dimension,
            output_shape=output_shape,
            activation_function=activation_function,
            initializer_mean=initializer_mean,
            initializer_deviation=initializer_deviation,
            dropout_decay_rate_g=dropout_decay_rate_g,
            last_layer_activation=last_layer_activation,
            dense_layer_sizes_g=dense_layer_sizes_g,
            dataset_type=dataset_type,
            number_samples_per_class=number_samples_per_class
        )

        # Initialize discriminator
        self._discriminator = VanillaDiscriminator(
            latent_dimension=latent_dimension,
            output_shape=output_shape,
            activation_function=activation_function,
            initializer_mean=initializer_mean,
            initializer_deviation=initializer_deviation,
            dropout_decay_rate_d=dropout_decay_rate_d,
            last_layer_activation=last_layer_activation,
            dense_layer_sizes_d=dense_layer_sizes_d,
            dataset_type=dataset_type,
            number_samples_per_class=number_samples_per_class
        )

    def get_generator(self):
        """
        Returns the generator model.

        Returns:
            Model/nn.Module: The generator model (TensorFlow Model or PyTorch nn.Module).
        """
        return self._generator.get_generator()

    def get_discriminator(self):
        """
        Returns the discriminator model.

        Returns:
            Model/nn.Module: The discriminator model (TensorFlow Model or PyTorch nn.Module).
        """
        return self._discriminator.get_discriminator()

    def get_dense_generator_model(self):
        """
        Returns the generator's dense model (without conditioning).

        Returns:
            Model/nn.Module: The dense model of the generator.
        """
        return self._generator.get_dense_generator_model()

    def get_dense_discriminator_model(self):
        """
        Returns the discriminator's dense model (without conditioning).

        Returns:
            Model/nn.Module: The dense model of the discriminator.
        """
        return self._discriminator.get_dense_discriminator_model()

    def set_latent_dimension(self, latent_dimension: int) -> None:
        """
        Sets the latent dimension for both the generator and discriminator.

        Note: This only updates the stored value. To apply changes, you need to 
        rebuild the models by creating a new AdversarialModel instance.

        Args:
            latent_dimension (int): New latent dimension value.
        """
        if not isinstance(latent_dimension, int) or latent_dimension <= 0:
            raise ValueError("latent_dimension must be a positive integer.")
        self._latent_dimension = latent_dimension
        self._generator._generator_latent_dimension = latent_dimension
        self._discriminator._discriminator_latent_dimension = latent_dimension

    def set_output_shape(self, output_shape: int) -> None:
        """
        Sets the output shape for both the generator and discriminator.

        Note: This only updates the stored value. To apply changes, you need to 
        rebuild the models by creating a new AdversarialModel instance.

        Args:
            output_shape (int): New output shape value.
        """
        if not isinstance(output_shape, int) or output_shape <= 0:
            raise ValueError("output_shape must be a positive integer.")
        self._output_shape = output_shape
        self._generator._generator_output_shape = output_shape
        self._discriminator._discriminator_output_shape = output_shape

    def set_activation_function(self, activation_function: str) -> None:
        """
        Sets the activation function for both the generator and discriminator.

        Note: This only updates the stored value. To apply changes, you need to 
        rebuild the models by creating a new AdversarialModel instance.

        Args:
            activation_function (str): New activation function.
        """
        if not isinstance(activation_function, str):
            raise ValueError("activation_function must be a string.")
        self._activation_function = activation_function
        self._generator._generator_activation_function = activation_function
        self._discriminator._discriminator_activation_function = activation_function

    def set_last_layer_activation(self, last_layer_activation: str) -> None:
        """
        Sets the last layer activation function for both the generator and discriminator.

        Note: This only updates the stored value. To apply changes, you need to 
        rebuild the models by creating a new AdversarialModel instance.

        Args:
            last_layer_activation (str): New activation function for the last layer.
        """
        if not isinstance(last_layer_activation, str):
            raise ValueError("last_layer_activation must be a string.")
        self._last_layer_activation = last_layer_activation
        self._generator._generator_last_layer_activation = last_layer_activation
        self._discriminator._discriminator_last_layer_activation = last_layer_activation

    def set_dataset_type(self, dataset_type: type) -> None:
        """
        Sets the dataset type for both the generator and discriminator.

        Note: This only updates the stored value. To apply changes, you need to 
        rebuild the models by creating a new AdversarialModel instance.

        Args:
            dataset_type (type): New dataset type.
        """
        self._dataset_type = dataset_type
        self._generator._generator_dataset_type = dataset_type
        self._discriminator._discriminator_dataset_type = dataset_type

    def set_initializer_mean(self, initializer_mean: float) -> None:
        """
        Sets the initializer mean for both the generator and discriminator.

        Note: This only updates the stored value. To apply changes, you need to 
        rebuild the models by creating a new AdversarialModel instance.

        Args:
            initializer_mean (float): New mean for parameter initialization.
        """
        if not isinstance(initializer_mean, (float, int)):
            raise ValueError("initializer_mean must be a float or an integer.")
        self._initializer_mean = initializer_mean
        self._generator._generator_initializer_mean = initializer_mean
        self._discriminator._discriminator_initializer_mean = initializer_mean

    def set_initializer_deviation(self, initializer_deviation: float) -> None:
        """
        Sets the initializer deviation for both the generator and discriminator.

        Note: This only updates the stored value. To apply changes, you need to 
        rebuild the models by creating a new AdversarialModel instance.

        Args:
            initializer_deviation (float): New deviation for parameter initialization.
        """
        if not isinstance(initializer_deviation, (float, int)) or initializer_deviation <= 0:
            raise ValueError("initializer_deviation must be a positive float or integer.")
        self._initializer_deviation = initializer_deviation
        self._generator._generator_initializer_deviation = initializer_deviation
        self._discriminator._discriminator_initializer_deviation = initializer_deviation

    def set_dropout_decay_rate_generator(self, dropout_decay_rate_g: float) -> None:
        """
        Sets the dropout decay rate for the generator.

        Args:
            dropout_decay_rate_g (float): New dropout decay rate for generator.
        """
        self._generator.set_dropout_decay_rate_generator(dropout_decay_rate_g)
        self._dropout_decay_rate_g = dropout_decay_rate_g

    def set_dropout_decay_rate_discriminator(self, dropout_decay_rate_d: float) -> None:
        """
        Sets the dropout decay rate for the discriminator.

        Args:
            dropout_decay_rate_d (float): New dropout decay rate for discriminator.
        """
        self._discriminator.set_dropout_decay_rate_discriminator(dropout_decay_rate_d)
        self._dropout_decay_rate_d = dropout_decay_rate_d

    def set_dense_layer_sizes_generator(self, dense_layer_sizes_g: List[int]) -> None:
        """
        Sets the dense layer sizes for the generator.

        Args:
            dense_layer_sizes_g (List[int]): New dense layer sizes for generator.
        """
        self._generator.set_dense_layer_sizes_generator(dense_layer_sizes_g)
        self._dense_layer_sizes_g = dense_layer_sizes_g

    def set_dense_layer_sizes_discriminator(self, dense_layer_sizes_d: List[int]) -> None:
        """
        Sets the dense layer sizes for the discriminator.

        Args:
            dense_layer_sizes_d (List[int]): New dense layer sizes for discriminator.
        """
        self._discriminator.set_dense_layer_sizes_discriminator(dense_layer_sizes_d)
        self._dense_layer_sizes_d = dense_layer_sizes_d

    def get_latent_dimension(self) -> int:
        """Returns the current latent dimension."""
        return self._latent_dimension

    def get_output_shape(self) -> int:
        """Returns the current output shape."""
        return self._output_shape

    def get_activation_function(self) -> str:
        """Returns the current activation function."""
        return self._activation_function

    def get_last_layer_activation(self) -> str:
        """Returns the current last layer activation."""
        return self._last_layer_activation

    def get_dropout_decay_rate_generator(self) -> float:
        """Returns the current generator dropout rate."""
        return self._dropout_decay_rate_g

    def get_dropout_decay_rate_discriminator(self) -> float:
        """Returns the current discriminator dropout rate."""
        return self._dropout_decay_rate_d

    def get_dense_layer_sizes_generator(self) -> List[int]:
        """Returns the current generator dense layer sizes."""
        return self._dense_layer_sizes_g.copy()

    def get_dense_layer_sizes_discriminator(self) -> List[int]:
        """Returns the current discriminator dense layer sizes."""
        return self._dense_layer_sizes_d.copy()

    def rebuild_models(self) -> None:
        """
        Rebuilds both generator and discriminator models with current configuration.
        Useful after changing model parameters.
        """
        self._generator = VanillaGenerator(
            latent_dimension=self._latent_dimension,
            output_shape=self._output_shape,
            activation_function=self._activation_function,
            initializer_mean=self._initializer_mean,
            initializer_deviation=self._initializer_deviation,
            dropout_decay_rate_g=self._dropout_decay_rate_g,
            last_layer_activation=self._last_layer_activation,
            dense_layer_sizes_g=self._dense_layer_sizes_g,
            dataset_type=self._dataset_type,
            number_samples_per_class=self._number_samples_per_class
        )

        self._discriminator = VanillaDiscriminator(
            latent_dimension=self._latent_dimension,
            output_shape=self._output_shape,
            activation_function=self._activation_function,
            initializer_mean=self._initializer_mean,
            initializer_deviation=self._initializer_deviation,
            dropout_decay_rate_d=self._dropout_decay_rate_d,
            last_layer_activation=self._last_layer_activation,
            dense_layer_sizes_d=self._dense_layer_sizes_d,
            dataset_type=self._dataset_type,
            number_samples_per_class=self._number_samples_per_class
        )
